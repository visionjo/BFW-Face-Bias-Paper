 \documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4

%\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out
                                                          % if you need a4paper
                                                          
\usepackage{FG2019}
\usepackage{multirow}
\newcommand{\minitab}[2][c]{\begin{tabular}{#1}#2\end{tabular}}
\usepackage[acronym]{glossaries}
\usepackage{acronym}
\usepackage{bigstrut}
% symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{amssymb}
\usepackage{amsmath}% assumes amsmath package installed
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
% \usepackage{hyperref}       % hyperlinks
\usepackage[colorlinks = true,
            linkcolor = blue,
            urlcolor  = blue,
            citecolor = blue,
            anchorcolor = blue]{hyperref}
            
\usepackage{url}            % simple URL typesetting
\usepackage{mathptmx} % assumes new font selection scheme installed
\usepackage{times} % assumes new font selection scheme installed
\usepackage{lipsum}
% \usepackage{slashbox}
\usepackage{booktabs}       % professional-quality tables
%\usepackage{enumitem}
\usepackage [english]{babel}
\usepackage [autostyle, english = american]{csquotes}
\MakeOuterQuote{"}
\usepackage[font=itshape]{quoting}
\usepackage{lipsum}
% \usepackage{subfig}
%% add
\usepackage{tikz}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{color, colortbl}
\usepackage{comment}
\usepackage{tabularx, booktabs, ragged2e}
\usepackage{arydshln}
\usepackage{todonotes}
\usepackage{ctable}
\usepackage{multirow}
\usepackage{makecell}

% \usepackage[small]{caption}
% \usepackage{subcaption}
% \usepackage{subfigure} 
\usepackage{sidecap}
\usepackage{wrapfig}
\usepackage[subrefformat=parens,labelformat=parens]{subcaption} %% provides subfigure
\usepackage{caption}
\usepackage{adjustbox}
\usepackage{float}% If comment this, figure moves
\usepackage{geometry}

%\usepackage{algorithm}
%\usepackage{algorithmic}
%\usepackage[]{algorithm2e}
%\usepackage{amssymb}% http://ctan.org/pkg/amssymb
\usepackage{pifont}% http://ctan.org/pkg/pifont


\graphicspath{{images/}} %Setting the graphicspath
\usepackage{bibunits}

\defaultbibliography{bias}
\defaultbibliographystyle{ieee}

\usepackage{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}


\usepackage{array}
\newcolumntype{x}[1]{>{\centering\arraybackslash\hspace{0pt}}p{#1}}

% \import{sections/}{experimental.tex}
% \import{sections/}{analysis.tex}

% \newcommand{\argmax}{\mathop{\mathrm{argmax}}\limits} 
\newcommand{\argmax}{\mathop{\mathrm{argmax}}\limits} 
\newcommand{\argmin}{\mathop{\mathrm{argmin}}\limits} 

\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\newcommand{\xmark}{\ding{56}}%
\newcommand{\checkc}{\ding{51}}%

\newcommand{\com}[1]{\textcolor{red}{#1}}
\newcommand{\ie}{\textit{i}.\textit{e}., }
\newcommand{\eg}{\textit{e}.\textit{g}., }
\newcommand*{\etc}{etc.\@\xspace}


\newcommand{\yann}[1]{\todo[color=orange!40]{\rotatebox{90}{YANN: #1}}}
\newcommand{\samson}[1]{\todo[color=blue!40]{\rotatebox{90}{SAMSON: #1}}}
\newcommand{\joe}[1]{\todo[color=purple!40]{\rotatebox{90}{JOE: #1}}}
\newcommand{\bob}[1]{\todo[color=green!40]{\rotatebox{90}{BOB: #1}}}
\newcommand{\gena}[1]{\todo[color=orange!40]{\rotatebox{90}{GENA: #1}}}


\newacronym{m}{M}{\textit{Male}}
\newacronym{f}{F}{\textit{Female}}
\newacronym{a}{A}{\textit{Asian}}
\newacronym{b}{B}{\textit{Black}}
\newacronym{i}{I}{\textit{Indian}}
\newacronym{w}{W}{\textit{White}}
\newacronym{af}{AF}{\textit{Asian}-\textit{Female}}
\newacronym{am}{AM}{\textit{Asian}-\textit{Male}}
\newacronym{bf}{BF}{\textit{Black}-\textit{Female}}
\newacronym{bm}{BM}{\textit{Black}-\textit{Male}}
\newacronym{if}{IF}{\textit{Indian}-\textit{Female}}
\newacronym{im}{IM}{\textit{Indian}-\textit{Male}}
\newacronym{wf}{WF}{\textit{White}-\textit{Female}}
\newacronym{wm}{WM}{\textit{White}-\textit{Male}}

\newacronym{ml}{ML}{machine learning}
\newacronym{fr}{FR}{facial recognition}
\newacronym{fv}{FV}{facial verification}

\newacronym{cnn}{CNN}{convolutional neural network}
\newacronym{nn}{NN}{neural network}
\newacronym{mtcnn}{MTCNN}{\emph{multi-task \gls{cnn}}}

\newacronym{gan}{GAN}{generative adversarial network}
\newacronym{se}{SE}{\emph{Squeeze-and-Excitation}}
\newacronym{d}{$D$}{discriminator}
\newacronym{g}{$G$}{generator}
\newacronym{dbvae}{DB-VAE}{Debiasing Variational Autoencoder}


\newacronym{lut}{LUT}{Look-Up-Table}
\newacronym{soa}{SOTA}{state-of-the-art}

\newacronym{fiw}{FIW}{Families In the Wild}
\newacronym{lfw}{LFW}{Labeled Faces in the Wild}
\newacronym{bfw}{BFW}{Balanced Faces In the Wild}
\newacronym{rfw}{RFW}{Racial Faces in-the-Wild:}
\newacronym{dp}{DemogPairs}{Demographic Pairs}
\newacronym{itwcc}{ITWCC}{Wild Child Celebrity}

\newacronym{fd}{FD}{Face Discrimination}
\newacronym{bb}{BB}{bounding box}

\newacronym{sdm}{SDM}{signal detection model}
\newacronym{roc}{ROC}{receiver operating characteristic}
\newacronym{nmse}{NMSE}{Normalized Mean Square Error}
\newacronym{det}{DET}{Detection Error Trade-off}
\newacronym{tp}{TP}{true-positive}
\newacronym{fp}{FP}{false-positive}

\newacronym{tpir}{TPIR}{true-positive identification rate}
\newacronym{frir}{FRIR}{false-reject identification rate}
\newacronym{fpir}{FRIR}{false-positive identification rate}

\newacronym{fn}{FN}{false-negative}
\newacronym{frr}{FRR}{false-reject rate}
\newacronym{fnr}{FNR}{false-negative rate}

\newacronym{fpr}{FPR}{false-positive rate}
\newacronym{tpr}{TPR}{true-positive rate}


\newacronym{tar}{TAR}{True Acceptance Rate}
\newacronym{far}{FAR}{False Acceptance Rate}
\newacronym{eer}{EER}{Equal Error Rate}

\newacronym{cs}{CS}{Cosine Similiarity}


\newacronym{lime}{LIME}{Local Interpretable Model-Agnostic Explanations}
\newacronym{nas}{NAS}{Neural Architecture Search}
\newacronym{gapf}{GAPF}{Generative Adversarial Privacy and Fairness}
 
                                                          % paper
%\setlist[itemize]{leftmargin=*}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}
\newcommand{\mc}[2]{\multicolumn{#1}{c}{#2}}
\definecolor{Gray}{gray}{0.85}
\definecolor{LightCyan}{rgb}{0.88,1,1}

\newcolumntype{a}{>{\columncolor{Gray}}c}
\newcolumntype{b}{>{\columncolor{white}}c}
\renewcommand{\arraystretch}{1.4}
%\newcommand{\xmark}{\ding{53}}%

\newcommand{\highlightb}[1]{%
\colorbox{blue!30}{$\displaystyle#1$}}
\newcommand{\vo}{\vec{o}\@ifnextchar{^}{\,}{}}

\newcommand{\vx}{\vec{x}\@ifnextchar{^}{\,}{}}

\FGfinalcopy % *** Uncomment this line for the final submission
\let\vec\mathbf


% \IEEEoverridecommandlockouts                              % This command is only
                                                          % needed if you want to
                                                          % use the \thanks command
% \overrideIEEEmargins
% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files



\title{\LARGE \bf\vspace{-10mm}
Face Recognition: Too Bias, or Not Too Bias?
}


%use this in case of several affiliations
\author{\parbox{16cm}{\centering
    {\large Joseph P Robinson$^1$, Gennady Livitz$^2$, Yann Henon$^2$, Can Qin$^1$,\\ Yun Fu$^1$, and Samson Timoner$^2$}\\
    {\normalsize
    \hspace{-.4in}$^{1}$Northeastern University\hspace{.7in} $^{2}$ISM Connect}}
    \thanks{}% <-this % stops a space
}

\begin{document}
%\begin{bibunit}


\def\angle{0}
\def\radius{3}
\def\cyclelist{{"orange","blue","red","green","magenta","cyan"}}
\newcount\cyclecount \cyclecount=-1
\newcount\ind \ind=-1

\ifFGfinal
\thispagestyle{empty}
\pagestyle{empty}
\else
\author{Anonymous FG 2019 submission\\ Paper ID \FGPaperID \\}
\pagestyle{plain}
\fi
\maketitle


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
We reveal critical insights into problems of bias in state-of-the-art \gls{fr} systems using a novel \gls{bfw} dataset: data balanced for gender and ethnic groups. Classic signal detection theory revealed trends in the underlying score distribution across subgroups. Specifically, we show variations in the optimal scoring threshold varies for face-pairs across different subgroups. Thus, the conventional approach of learning a  global threshold for all pairs resulting in performance gaps among subgroups. By learning subgroup-specific thresholds, we not only mitigate problems in performance gaps but also show a notable boost in the overall performance. Furthermore, we do a human evaluation to measure the bias in humans, which supports the hypothesis that such a bias exists in human perception. To download the \gls{bfw} database, source code, and more, visit \href{https://github.com/visionjo/facerec-bias-bfw}{github.com/visionjo/facerec-bias-bfw}
\end{abstract}
\
\input{sections/introduction.tex}


\input{sections/relatedworks.tex}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{sections/section3.tex}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\input{sections/analysis.tex}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[t!]
\begin{center}
    \caption{\small{\textbf{Quantitative of human assessment.} Different human subgroups listed per row. Each column is the subgroup labeled. Note that each people are best within their subgroup, and second-best within the same subgroup but different gender. CF shows the least variation, but with the lowest accuracy. CM shows the best accuracy, but second to \gls{wm} in deviation from the mean. Thus, scores for males vary more than females.}}
    \label{tab:humsn-eval-results} 
     \vspace{-2mm}

\footnotesize
\scalebox{0.9}{
\begin{tabular}{l c c c c c}
        &  CF  &      CM     &   WF     &   WM     &  Avg\\\midrule
        CF &  \textbf{0.529}&  0.480&0.438&0.447 &0.474$\pm$0.041 \\
        CM & 0.456 & \textbf{0.504}  & 0.444 &0.362 &0.441$\pm$0.059 \\
        WF & 0.447 &0.438 &  \textbf{0.573}& 0.480 & 0.485$\pm$0.062 \\
        WM & 0.301&0.474 &  0.453 & \textbf{0.561} & 0.447$\pm$0.108 \\\midrule
        Avg &  0.433& 0.474&0.477 &0.463 &0.462$\pm$0.020\\
 \end{tabular}}
 \end{center}
 \vspace{-6mm}
\end{table} 

\glsresetall
\vspace{-1mm}
\section{CONCLUSION}
We introduce a new data set \gls{bfw} with eight subgroups balanced across gender and ethnicity. With this, and upon highlighting the challenges and shortcomings of grouping subjects as a single subset, we provide evidence that forming subgroups is meaningful, as the \gls{fr} algorithm rarely makes mistakes across subgroups. We trained Arc-Face net on MSCeleb, expecting that the results would suffer from bias because of the imbalanced train-set. Once established that the results do suffer from problems of bias, we observed that the same threshold across ethnic and gender subgroups leads to differences in the \gls{fpr} up to a factor of two, which is seemingly the cause of the frenzy about bias in \gls{fr} in main-stream media. Furthermore, we ameliorate these differences with a per-subgroup threshold, leveling out \gls{fpr}, and achieving a higher \gls{tpr}. We hypothesized that most humans grown amongst more than their own demographic and, therefore, effectively learn from imbalanced datasets-- a human evaluation validated that humans are biased, as most recognized their personal demographic best. The focused research findings presented here, along with the public database included, are extendable in vast ways. Thus, we see this as the slither to a much larger problem of bias in ML.

\vspace{-3mm}
\bibliographystyle{ieee}
\bibliography{bias}

% \putbib
% \end{bibunit}
\begin{bibunit}
\input{supplemental.tex}
\end{bibunit}

\end{document}